{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the adjacency matrix for village 1\n",
    "df = pd.read_csv(\n",
    "    \"data/Network Data/Adjacency Matrices/adj_allVillageRelationships_HH_vilno_1.csv\",\n",
    "    header=None,\n",
    ")\n",
    "\n",
    "# Change it into matrix form\n",
    "adj_all_v1 = df.values\n",
    "print(adj_all_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot the adjacency matrix - Blue:connection and White:no connection\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(adj_all_v1, cmap=\"Blues\", interpolation=\"none\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Adjacency Matrix\")\n",
    "plt.xlabel(\"Node ID\")\n",
    "plt.ylabel(\"Node ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the graph from the adjacency matrix\n",
    "G = nx.from_numpy_array(adj_all_v1)\n",
    "print(f\"Number of nodes in G: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges in G: {G.number_of_edges()}\")\n",
    "\n",
    "# Compute the average degree of the graph, which is the number of edges a node in the network has on average. Average degree is measured as total_no_of_edges/total_no_of_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot the graph for visualisation\n",
    "plt.figure(figsize=(5, 5))\n",
    "pos = nx.random_layout(G, seed=127)  # We select random layout for nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_color=\"black\", node_size=100)\n",
    "nx.draw_networkx_edges(G, pos, edge_color=\"gray\", width=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a better way to visualise the network?\n",
    "plt.figure(figsize=(5, 5))\n",
    "pos = nx.spring_layout(G, seed=7)\n",
    "nx.draw_networkx_nodes(G, pos, node_color=\"black\", node_size=100)\n",
    "nx.draw_networkx_edges(G, pos, edge_color=\"gray\", width=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the biggest connected component of the network for analysis\n",
    "G_giant = G.subgraph(max(nx.connected_components(G), key=len)).copy()\n",
    "\n",
    "# Relabel nodes in the Giant component from 1 to N, where N is the number of nodes in the giant component\n",
    "node_labels_old = list(G_giant.nodes())\n",
    "node_labels_new = list(range(0, len(node_labels_old) + 1))\n",
    "\n",
    "node_label_map = dict(zip(node_labels_old, node_labels_new))\n",
    "\n",
    "G_final = nx.relabel_nodes(G_giant, node_label_map)\n",
    "\n",
    "# We save the node mapping\n",
    "node_labels_df = pd.DataFrame(\n",
    "    {\n",
    "        \"original_node_label\": node_labels_old,\n",
    "        \"new_node_label\": [node_label_map[old_label] for old_label in node_labels_old],\n",
    "    }\n",
    ")\n",
    "node_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Print the no of nodes, edges and the average degree in the giant component. Has the average degree changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the giant component using force layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now compute the centrality metrics for nodes in the giant component\n",
    "degree_centrality = nx.degree_centrality(G_final)\n",
    "closeness_centrality = nx.closeness_centrality(G_final)\n",
    "betweenness_centrality = nx.betweenness_centrality(G_final)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G_final)\n",
    "\n",
    "centralities = {\n",
    "    \"Degree\": degree_centrality,\n",
    "    \"Closeness\": closeness_centrality,\n",
    "    \"Betweenness\": betweenness_centrality,\n",
    "    \"Eigenvector\": eigenvector_centrality,\n",
    "}\n",
    "\n",
    "# We plot the distribution of the centralities\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "#\n",
    "for i, (title, data) in enumerate(centralities.items()):\n",
    "    axs[i].hist(list(data.values()), bins=20)\n",
    "    axs[i].set_xlabel(f\"{title}\")\n",
    "    axs[i].set_ylabel(\"Freq\")\n",
    "    axs[i].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store the centralities in a dataframe\n",
    "centrality_df = pd.merge(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"node\": list(degree_centrality.keys()),\n",
    "            \"degree_centrality\": list(degree_centrality.values()),\n",
    "            \"closeness_centrality\": list(closeness_centrality.values()),\n",
    "            \"betweenness_centrality\": list(betweenness_centrality.values()),\n",
    "            \"eigenvector_centrality\": list(eigenvector_centrality.values()),\n",
    "        }\n",
    "    ),\n",
    "    node_labels_df,\n",
    "    left_on=\"node\",\n",
    "    right_on=\"new_node_label\",\n",
    ").drop(columns=[\"new_node_label\"])\n",
    "print(\n",
    "    centrality_df.sort_values(by=\"degree_centrality\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the network again and colour nodes based on their degree centrality\n",
    "node_color = [degree_centrality[node] for node in G_final.nodes()]\n",
    "\n",
    "pos = nx.spring_layout(G_final, seed=7, k=0.01, iterations=100)\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G_final,\n",
    "    pos,\n",
    "    node_color=node_color,\n",
    "    cmap=plt.cm.viridis,\n",
    "    node_size=500,\n",
    "    alpha=0.75,\n",
    "    ax=ax,\n",
    ")\n",
    "nx.draw_networkx_edges(G_final, pos, alpha=0.3, ax=ax)\n",
    "nx.draw_networkx_labels(G_final, pos, font_size=8, font_color=\"white\")\n",
    "\n",
    "sm = plt.cm.ScalarMappable(\n",
    "    cmap=plt.cm.viridis, norm=plt.Normalize(vmin=min(node_color), vmax=max(node_color))\n",
    ")\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort nodes based on closeness centrality and print the top 5 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the network again and colour nodes based on their closeness centrality - does it look different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For all 75 villages compute the avg centralities [Advanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add characteristics of households to the centrality dataframe\n",
    "# First read in the demographics data\n",
    "demographics_df = pd.read_stata(\n",
    "    \"data/Demographics and Outcomes/household_characteristics.dta\"\n",
    ")\n",
    "# Filter for village 1\n",
    "demographics_v1 = demographics_df[demographics_df[\"village\"] == 1].copy()\n",
    "demographics_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join demographics data with the centrality dataframe\n",
    "# We have to match the node IDs\n",
    "demographics_v1[\"adjusted_key\"] = demographics_v1[\"adjmatrix_key\"] - 1\n",
    "node_centrality_and_demographics = pd.merge(\n",
    "    centrality_df,\n",
    "    demographics_v1,\n",
    "    left_on=\"original_node_label\",\n",
    "    right_on=\"adjusted_key\",\n",
    "    how=\"left\",\n",
    ")\n",
    "node_centrality_and_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average degree centrality of leaders and non-leaders\n",
    "grp_col = \"degree_centrality\"\n",
    "group_by_leader_status = (\n",
    "    node_centrality_and_demographics.groupby(\"leader\")[grp_col]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.bar(\n",
    "    group_by_leader_status[\"leader\"],\n",
    "    group_by_leader_status[\"mean\"],\n",
    "    yerr=group_by_leader_status[\"std\"],\n",
    "    capsize=5,\n",
    "    color=[\"grey\", \"indianred\"],\n",
    "    tick_label=[\"Non-leader\", \"Leader\"],\n",
    ")\n",
    "\n",
    "plt.xticks([0, 1])\n",
    "plt.ylabel(grp_col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average closeness centrality of leaders and non-leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define diffusion model\n",
    "def run_simulation(N, T, qN, qP, pP, seed_nodes, beta, seed=42):\n",
    "    # initialise the node sets\n",
    "    np.random.seed(seed)\n",
    "    informed_nodes = np.zeros(N)\n",
    "    participant_nodes = np.zeros(N)\n",
    "\n",
    "    # 0 - uninformed node, 1 - informed node\n",
    "    informed_nodes[seed_nodes] = 1\n",
    "\n",
    "    # We extract the informed node set. We do this because each node has only one shot at adopting microfinance\n",
    "    newly_informed_nodes_list = seed_nodes\n",
    "\n",
    "    infection_rate = []\n",
    "\n",
    "    for t in range(1, T):\n",
    "        participant_node_list = []\n",
    "\n",
    "        #  Adoption process\n",
    "        for newly_informed_node in newly_informed_nodes_list:\n",
    "            neighbours = list(G_final.neighbors(newly_informed_node))\n",
    "\n",
    "            # We transform node characteristics and neighbour effects into probability of adoption using a logistic function\n",
    "            if np.random.rand() <= 1 / (\n",
    "                1\n",
    "                + np.exp(\n",
    "                    -(\n",
    "                        beta[0] * pP[newly_informed_node]\n",
    "                        + beta[1] * sum(participant_nodes[neighbours])\n",
    "                    )\n",
    "                )\n",
    "            ):\n",
    "                participant_node_list.append(newly_informed_node)\n",
    "\n",
    "        participant_nodes[participant_node_list] = 1\n",
    "\n",
    "        infection_rate.append(sum(participant_nodes) / N)\n",
    "\n",
    "        informed_nodes[newly_informed_nodes_list] = 1\n",
    "        informed_nodes_list = np.where(informed_nodes == 1)[0]\n",
    "\n",
    "        newly_informed_nodes_list = []\n",
    "\n",
    "        #  Transmission process\n",
    "        for informed_node in informed_nodes_list:\n",
    "            if (participant_nodes[informed_node] == 1 and np.random.rand() <= qP) or (\n",
    "                participant_nodes[informed_node] == 0 and np.random.rand() <= qN\n",
    "            ):\n",
    "                newly_informed_nodes_list.extend(\n",
    "                    [\n",
    "                        n\n",
    "                        for n in G_final.neighbors(informed_node)\n",
    "                        if informed_nodes[n] == 0\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    return infection_rate, informed_nodes, participant_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "N = G_final.number_of_nodes()  # number of individuals\n",
    "T = 25\n",
    "qN = 0.01  # probability that a non-taker transmits info\n",
    "qP = 0.1  # probability that a taker transmits info\n",
    "pP = np.random.randint(0, 2, size=N)  # randomly generate household characteristics\n",
    "f = 0.1\n",
    "beta = np.array([1, 1])\n",
    "\n",
    "centrality_measure = \"degree_centrality\"\n",
    "\n",
    "seed_nodes = (\n",
    "    centrality_df.sort_values(by=centrality_measure, ascending=False)\n",
    "    .reset_index()\n",
    "    .head(round(f * N))[\"node\"]\n",
    "    .values\n",
    ")\n",
    "infection_rate, informed_nodes, participant_nodes = run_simulation(\n",
    "    N, T, qN, qP, pP, seed_nodes, beta\n",
    ")\n",
    "\n",
    "node_colors = [\"indianred\" if participant_nodes[i] == 1 else \"black\" for i in range(N)]\n",
    "pos = nx.spring_layout(G_final, seed=7, k=0.01, iterations=100)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "\n",
    "axes[0].plot(infection_rate, marker=\"o\")\n",
    "axes[0].set_xlabel(\"T\")\n",
    "axes[0].set_ylabel(\"Uptake Rate\")\n",
    "\n",
    "\n",
    "nx.draw_networkx_nodes(\n",
    "    G_final, pos, node_color=node_colors, node_size=300, alpha=0.7, ax=axes[1]\n",
    ")\n",
    "nx.draw_networkx_edges(G_final, pos, edge_color=\"gray\", ax=axes[1])\n",
    "axes[1].set_title(\"Red = Participant; Black = Does not participate\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "N = G_final.number_of_nodes()  # number of individuals\n",
    "T = 25\n",
    "qN = 0.01  # probability that a non-taker transmits info\n",
    "qP = 0.1  # probability that a taker transmits info\n",
    "pP = np.random.randint(0, 2, size=N)  # randomly generate household characteristics\n",
    "f = 0.1\n",
    "beta = np.array([1, 1])\n",
    "\n",
    "centrality_measure = \"degree_centrality\"\n",
    "\n",
    "seed_nodes = (\n",
    "    centrality_df.sort_values(by=centrality_measure, ascending=False)\n",
    "    .reset_index()\n",
    "    .head(round(f * N))[\"node\"]\n",
    "    .values\n",
    ")\n",
    "infection_rate, informed_nodes, participant_nodes = run_simulation(\n",
    "    N, T, qN, qP, pP, seed_nodes, beta\n",
    ")\n",
    "\n",
    "infection_rate_random = []\n",
    "for i in range(100):\n",
    "    random_seed = np.random.randint(0, N, round(f * N))\n",
    "    infection_rate_rand, informed_nodes_rand, participant_nodes_rand = run_simulation(\n",
    "        N, T, qN, qP, pP, random_seed, beta\n",
    "    )\n",
    "\n",
    "    infection_rate_random.append(infection_rate_rand)\n",
    "\n",
    "mean_infection_rate_random = np.mean(np.array(infection_rate_random), axis=0)\n",
    "std_infection_rate_random = np.std(np.array(infection_rate_random), axis=0)\n",
    "\n",
    "node_colors = [\"indianred\" if participant_nodes[i] == 1 else \"black\" for i in range(N)]\n",
    "pos = nx.spring_layout(G_final, seed=7, k=0.01, iterations=100)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "plt.rcParams.update({\"font.size\": 18})\n",
    "\n",
    "axes[0].plot(infection_rate, marker=\"o\", label=centrality_measure)\n",
    "axes[0].errorbar(\n",
    "    np.arange(len(mean_infection_rate_random)),\n",
    "    mean_infection_rate_random,\n",
    "    yerr=std_infection_rate_random,\n",
    "    fmt=\"-o\",\n",
    "    capsize=5,\n",
    "    label=\"random\",\n",
    "    elinewidth=1,\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"T\")\n",
    "axes[0].set_ylabel(\"Uptake Rate\")\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "nx.draw_networkx_nodes(\n",
    "    G_final, pos, node_color=node_colors, node_size=300, alpha=0.7, ax=axes[1]\n",
    ")\n",
    "nx.draw_networkx_edges(G_final, pos, edge_color=\"gray\", ax=axes[1])\n",
    "axes[1].set_title(\"Red = Participant; Black = Not a participant\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed nodes based on other centrality measures - how do they each perform in comparison to each other?\n",
    "# Input characteristics from the node_centrality_and_demographics dataframe\n",
    "## Replicate diffusion model for other villages? Which centrality measure works the best on average?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
